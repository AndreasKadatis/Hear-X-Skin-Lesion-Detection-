Today is going to be the first day of the last tw weeks of my work with Hearx. I have been unable to work full days for the last
week and a half due to prior commitments, howver am now free to work full time again till the end of my internship. I will be work-
ing 10-11 hours a day for the next three days and then normal workdays this weekend, and then a normal work week next week to finish
and accumulate the requisite hours. The goal for today is to try a last couple of new techniques to get the validation accuracy of 
of the model higher. I've already started looking at the new layers that i want to add in conjuction with stronger L2 regularization.
Augmentation at this point is second priority, as the evidence seems that it might not be as effective as other potential 
methods. [1.5 hours] 

After looking at L2 regularization code examples, and again at how i implemented the layered augmentation i decided there might be
more value persuing better data augmentation vs regularization, as i dont think my attemt before was as good as i thought it was.
Ive made a few changes and added some additional class weights to see if i can make it better, and have it training now in the back-
ground. Ive also stumbled across an interesting way of using the ImageDataGenerator function, while also making use of python
inbuilt over-fitting functions, [https://medium.com/analytics-vidhya/how-to-apply-data-augmentation-to-deal-with-unbalanced-datasets
-in-20-lines-of-code-ada8521320c9] and will now work on bringing it in on a third version of the Mobilnet approach. [2 hours]

The third run of the previous augmentation method previously mentioned (after making several changes) produced no substantial 
improvement, still level at 84% validation accuracy. Also after trying to get this example working in my code [https://medium
.com/analytics-vidhya/how-to-apply-data-augmentation-to-deal-with-unbalanced-datasets-in-20-lines-of-code-ada8521320c9] i realised
that it follows a completely different way of loading the images into the model and training it. After reading up on the different
loading methods for images, i realised once again just how inexperienced i am with the detail of python and its associated libraries.
It will take quite a while (at least a couple of hours) for me to figure out a way to get the images into a format that would
work, and i am still not 100% sure it would work. I am therefore unsure if i should continue down this path. What i might do,
is explore other options more applicable to what ive done, and ask Jaco for advice with regards to this method. [2.5 hours] 

Im very conflicted at the moment in terms of how far i think this style of image classification can go. All the examples i have
worked through so far have really only gotten to around the accuracy i have been abe to achieve. There is also the unfortunate 
case that the ones that do achieve the 90% accuracies are exceedingly complex, so much so that it would be very time intensive
for me to work through. That being said, maybe i am being unneccessarily pessimistic, i will raise these issues with Jaco. I have
been therefore looking at models for other image classification tasks that claim much higher accuracies but are not neccesarily
applicable to our case, with this competition in particular catching my attention as possibly another avenue to follow [
https://www.kaggle.com/omkarsabnis/seedling-classification-using-cnn-v13-0-95]. [1 hour]

What i think ill do tomorrow is try to achieve some results using different layers for regularization. Today was very much a 
augmentation workthrough to difintively understand what the limitations are towards the skin lesion application. Hopefully
i can do the same tomorrow and be able to produce to Jaco a detailed outline of what my thoughts are and where to go from here. 
[1 hour]
