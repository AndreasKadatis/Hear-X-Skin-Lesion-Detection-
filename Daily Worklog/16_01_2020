Finished off yesterdays work by implementing the resnet architecture, results were indeed the same as in the cite previously 
referenced, however each run was extremely slow, 15-20 seconds at least. This may be because no layers are frozen and NN is 
training each layer. I will look into what can be done in this regard to speed up the process. What is apparent is that the 
heavy augmentation performed by the Mobilenet architecture can be done differently and still achieve strong results. [1 hour]

Started implmenting the VGG architecture into the standard model. Also did some more reading of what the other kernels have done 
with regards to freezing layers, and in particular in what models they did what techniques. Confusion still persists for me with
regards to the extra layers a lot of the DNN have added on to the standard in built keras models. How do you know what to add, 
what benefits does it increase? [1.5 hours]

After finishing the VGG model adjustments, and running it, the first two training rounds indicated high accuracy, in line with 
the Resnet implementation, but a little bit faster as the VGG version included the layere freezing tried previously in the VGG
version that failed. Unfortunately, it failed a third round as one of the images was reportedly corrupt. Examining the said image 
in the drive showed that it had not been uploaded properly. Previously when the new image preprocessing part collated the images
from the csv file to the actual images, it reported that a couple hundred images couldnt be matched. I didnt pay this much heed
as firstly i didnt know how to fix it, and second falsely assumed it didnt matter as it should only train the model on the val-
idated images. Evidently this was not the case and after trying several things to find all the corrupt images i have had to start
the re-upload of all the images in the HAM dataset. I can only think that in the initial upload something went wrong. Looking
at the folder on my physical hardrive, there seems to be about 300 images missing. its possible something happened when i merged
part 1 and 2 of the dataset together. In any case the upload is about halfway through at the moment, and in the meantime ive been
looking at different pre-processing methods i would like to try once its done and done correctly, as well as a fourth InceptionNet
model that looks promising. [3.5 hours]

Alright so when the re-upload finished and i ran the pre-processing part of the model, i again received notifications of non-val-
idated images. One thing that has severly limited my error solving in this regard is the latency with Google drive. I can barely
look into the main image folders without the computer freezing. Luckily everytime the process run failed, it reported an image 
that was corrupted as the reason the training stopped. After struggling with these drive issues yesterday and today i finally 
realised i should check the activity log, just on the off chance that whats happening is listed there. Two things were shown, one
that i had "edited" two of the images from a jpeg to a .txt file, and i had also "moved" 273 images to the trash. My experience
with google drive has been challenging to say the least so far. After correcting the mistakes made by the drive, i have restart-
ed the training process and indeed all looks fine so far (we'll see). All images have been validated at least. [2 hours]

The model trained succcesfully and i am happy to say the initial results look good. There is still a lot of tweaking to do and 
things to add in but hopefully im on the right track. Ive written up a summary of my results so far and sent it off to Jaco for
feed-back. [1 hour]  
